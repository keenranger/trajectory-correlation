{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behind-dover",
   "metadata": {},
   "source": [
    "\n",
    "# Import neccessary modules\n",
    "1 for matrix caculation, 2 for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-necklace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:28:46.911953Z",
     "start_time": "2021-03-03T00:28:46.907315Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from module.input_parser_old import input_parser\n",
    "from module import in_fun\n",
    "from module.torch import BinaryClassifier\n",
    "\n",
    "\n",
    "beacon_list = [f\"beacon{idx + 1}\" for idx in range(9)]\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "false-missouri",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:28:55.474585Z",
     "start_time": "2021-03-03T00:28:55.470918Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-detroit",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "python에서 csv파일을 읽어올때, 숫자만 있는것이 아닌 문자열이 포함된 데이터를 읽을 경우 느려지는 것 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alive-browse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:29:00.051366Z",
     "start_time": "2021-03-03T00:28:55.848437Z"
    }
   },
   "outputs": [],
   "source": [
    "data_1233_1 = input_parser(\n",
    "    pd.read_csv(\n",
    "        \"./data/1233/note20/customscenario02_20210223173056.csv\",\n",
    "        header=None,\n",
    "        low_memory=False,\n",
    "    )\n",
    ")\n",
    "data_1233_2 = input_parser(\n",
    "    pd.read_csv(\n",
    "        \"./data/1233/s20/customscenario02_20210223173056.csv\",\n",
    "        header=None,\n",
    "        low_memory=False,\n",
    "    )\n",
    ")\n",
    "data_1250 = input_parser(\n",
    "    pd.read_csv(\n",
    "        \"./data/1250/customscenario01_20210223150144.csv\", header=None, low_memory=False\n",
    "    )\n",
    ")\n",
    "data_1251 = input_parser(\n",
    "    pd.read_csv(\n",
    "        \"./data/1251/customscenario01_20201009224245.csv\", header=None, low_memory=False\n",
    "    )\n",
    ") \n",
    "data_list = [data_1233_1, data_1233_2, data_1250, data_1251]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-phase",
   "metadata": {},
   "source": [
    "# Gather data\n",
    "250 row(5초)의 데이터를 모아서, 한 row로 묶어서 처리하였다. RSSI는 250 row중 최댓값을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "round-custody",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:29:00.076533Z",
     "start_time": "2021-03-03T00:29:00.053809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 9)\n",
      "(17, 9)\n",
      "(358, 9)\n",
      "(368, 9)\n"
     ]
    }
   ],
   "source": [
    "gathered_list = []\n",
    "for data in data_list:\n",
    "    cur_gathered = np.zeros([np.shape(data)[0] // 250, 9])\n",
    "    for row in range(np.shape(cur_gathered)[0]):\n",
    "        cur_gathered[row] = np.max(data[row * 250 : row * 250 + 250, -9:], axis=0)\n",
    "    cur_gathered += 100\n",
    "    cur_gathered = cur_gathered / 100\n",
    "    gathered_list.append(cur_gathered)\n",
    "    print(np.shape(gathered_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooperative-swimming",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:29:00.083751Z",
     "start_time": "2021-03-03T00:29:00.078828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 9)\n",
      "(358, 9)\n",
      "(368, 9)\n"
     ]
    }
   ],
   "source": [
    "gathered_1233 = np.concatenate((gathered_list[0], gathered_list[1]), axis=0)\n",
    "gathered_1250 = gathered_list[2]\n",
    "gathered_1251 = gathered_list[3]\n",
    "room_data = [gathered_1233, gathered_1250, gathered_1251]\n",
    "for room in room_data:\n",
    "    print(np.shape(room))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-assessment",
   "metadata": {},
   "source": [
    "# \"Same Room\" Data\n",
    "같은 방 데이터 끼리 매칭시키고, 그 둘 차의 절댓값으로 구성된 dim = 9의 input  \n",
    "146 * 146 + 1495 * 1495 + 1535 * 1535 = 4612566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264744, 18)\n"
     ]
    }
   ],
   "source": [
    "matched_same = []\n",
    "for room in room_data:\n",
    "    matched_same.append(in_fun.matcher(room, room))\n",
    "    \n",
    "same_diff = np.concatenate([same[0] for same in matched_same])\n",
    "same_each = np.concatenate([same[1] for same in matched_same])\n",
    "print(np.shape(same_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-reynolds",
   "metadata": {},
   "source": [
    "# \"Different Room\" Data\n",
    "다른 방 데이터 끼리 매칭시키고, 그 둘 차의 절댓값으로 구성된 dim = 9의 input  \n",
    "146 * 1495 + 1495 * 1535 + 1535 * 146 = 2737205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arctic-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.   -1.   -1.   -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.\n",
      "  -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.   -1.   -1.   -1.\n",
      "  -1.    0.14  0.17 -1.   -1.   -1.   -1.   -1.   -1.   -1.    0.14  0.17]\n",
      " [-1.   -1.   -1.   -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.\n",
      "  -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.   -1.   -1.   -1.\n",
      "  -1.    0.16  0.22 -1.   -1.   -1.   -1.   -1.   -1.   -1.    0.16  0.22]\n",
      " [-1.   -1.   -1.   -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.\n",
      "  -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.   -1.   -1.   -1.\n",
      "  -1.    0.16  0.16 -1.   -1.   -1.   -1.   -1.   -1.   -1.    0.16  0.16]\n",
      " [-1.   -1.   -1.   -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.\n",
      "  -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.   -1.   -1.   -1.\n",
      "  -1.    0.15  0.22 -1.   -1.   -1.   -1.   -1.   -1.   -1.    0.15  0.22]\n",
      " [-1.   -1.   -1.   -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.\n",
      "  -1.   -1.   -1.   -1.    0.23  0.32 -1.   -1.   -1.   -1.   -1.   -1.\n",
      "  -1.    0.14  0.22 -1.   -1.   -1.   -1.   -1.   -1.   -1.    0.14  0.22]]\n",
      "(156428, 36)\n"
     ]
    }
   ],
   "source": [
    "matched_diff = []\n",
    "matched_diff.append(in_fun.matcher(room_data[0], room_data[1]))\n",
    "matched_diff.append(in_fun.matcher(room_data[1], room_data[2]))\n",
    "matched_diff.append(in_fun.matcher(room_data[2], room_data[0]))\n",
    "\n",
    "diff_diff = np.concatenate([diff[0] for diff in matched_diff])\n",
    "diff_each = np.concatenate([diff[1] for diff in matched_diff])\n",
    "print(diff_each[54554:54559])\n",
    "print(np.shape(diff_each))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-decimal",
   "metadata": {},
   "source": [
    "# Loading data for nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "checked-reminder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:29:00.210922Z",
     "start_time": "2021-03-03T00:29:00.153577Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "x_tensor_diff = torch.from_numpy(np.concatenate((same_diff, diff_diff))).float()\n",
    "x_tensor_each = torch.from_numpy(np.concatenate((same_each, diff_each))).float()\n",
    "\n",
    "y = np.concatenate((np.zeros([len(same_each), 1]) + 1, np.zeros([len(diff_each), 1])))\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset_diff = TensorDataset(x_tensor_diff, y_tensor)\n",
    "dataset_each = TensorDataset(x_tensor_each, y_tensor)\n",
    "\n",
    "train_len_diff = len(dataset_diff) // 5 * 4\n",
    "train_len_each = len(dataset_each) // 5 * 4\n",
    "val_len_diff = len(dataset_diff) - train_len_diff\n",
    "val_len_each  = len(dataset_each) - train_len_each\n",
    "\n",
    "train_dataset_diff, val_dataset_diff = random_split(dataset_diff, [train_len_diff, val_len_diff])\n",
    "train_dataset_each, val_dataset_each = random_split(dataset_each, [train_len_each, val_len_each])\n",
    "\n",
    "train_loader_diff = DataLoader(dataset=train_dataset_diff, batch_size=32, shuffle=True)\n",
    "train_loader_each = DataLoader(dataset=train_dataset_each, batch_size=32, shuffle=True)\n",
    "val_loader_diff = DataLoader(dataset = val_dataset_diff, batch_size = val_len_diff)\n",
    "val_loader_each = DataLoader(dataset = val_dataset_each, batch_size = val_len_each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-punishment",
   "metadata": {},
   "source": [
    "# Layer\n",
    "nn 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collectible-overall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T00:29:00.253558Z",
     "start_time": "2021-03-03T00:29:00.219370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "documentary-butter",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-03T00:29:15.426Z"
    }
   },
   "outputs": [],
   "source": [
    "net_diff = BinaryClassifier(input_size = 18)\n",
    "net_each = BinaryClassifier(input_size = 36)\n",
    "net_diff.to(device)\n",
    "net_each.to(device)\n",
    "optimizer_diff = optim.SGD(net_diff.parameters(), lr=3e-3)\n",
    "optimizer_each = optim.SGD(net_each.parameters(), lr=3e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-complaint",
   "metadata": {},
   "source": [
    "비교분석을 위한 수치  \n",
    "모든 데이터에 true라고 응답해도, 정확도가 62%는 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assumed-source",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-03T00:30:53.847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6285887950765958\n"
     ]
    }
   ],
   "source": [
    "print(len(same_each) / (len(same_each) + len(diff_each)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "maritime-founder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Val Accuarcy : 99.20698988555962%\n",
      "epoch: 1, Val Accuarcy : 99.38149959637211%\n",
      "epoch: 2, Val Accuarcy : 99.48596799468162%\n",
      "epoch: 3, Val Accuarcy : 99.4990265444703%\n",
      "epoch: 4, Val Accuarcy : 99.54295075739589%\n",
      "epoch: 5, Val Accuarcy : 99.53107934849707%\n",
      "epoch: 6, Val Accuarcy : 99.60586922455957%\n",
      "epoch: 7, Val Accuarcy : 99.61536635167862%\n",
      "epoch: 8, Val Accuarcy : 99.61536635167862%\n",
      "epoch: 9, Val Accuarcy : 99.61536635167862%\n",
      "epoch: 10, Val Accuarcy : 99.62367633790778%\n",
      "epoch: 11, Val Accuarcy : 99.62605061968755%\n",
      "epoch: 12, Val Accuarcy : 99.62605061968755%\n",
      "epoch: 13, Val Accuarcy : 99.63079918324706%\n",
      "epoch: 14, Val Accuarcy : 99.63079918324706%\n",
      "epoch: 15, Val Accuarcy : 99.63910916947624%\n",
      "epoch: 16, Val Accuarcy : 99.63792202858636%\n",
      "epoch: 17, Val Accuarcy : 99.63317346502683%\n",
      "epoch: 18, Val Accuarcy : 99.64029631036611%\n",
      "epoch: 19, Val Accuarcy : 99.63910916947624%\n",
      "epoch: 20, Val Accuarcy : 99.64029631036611%\n",
      "epoch: 21, Val Accuarcy : 99.64979343748516%\n",
      "epoch: 22, Val Accuarcy : 99.64029631036611%\n",
      "epoch: 23, Val Accuarcy : 99.66403912816372%\n",
      "epoch: 24, Val Accuarcy : 99.65098057837504%\n",
      "epoch: 25, Val Accuarcy : 99.64504487392564%\n",
      "epoch: 26, Val Accuarcy : 99.64504487392564%\n",
      "epoch: 27, Val Accuarcy : 99.66403912816372%\n",
      "epoch: 28, Val Accuarcy : 99.66641340994349%\n",
      "epoch: 29, Val Accuarcy : 99.6652262690536%\n",
      "epoch: 30, Val Accuarcy : 99.67116197350302%\n",
      "epoch: 31, Val Accuarcy : 99.6972790730804%\n",
      "epoch: 32, Val Accuarcy : 99.66760055083337%\n",
      "epoch: 33, Val Accuarcy : 99.6723491143929%\n",
      "epoch: 34, Val Accuarcy : 99.66760055083337%\n",
      "epoch: 35, Val Accuarcy : 99.67353625528278%\n",
      "epoch: 36, Val Accuarcy : 99.68540766418158%\n",
      "epoch: 37, Val Accuarcy : 99.67353625528278%\n",
      "epoch: 38, Val Accuarcy : 99.68540766418158%\n",
      "epoch: 39, Val Accuarcy : 99.67472339617267%\n",
      "epoch: 40, Val Accuarcy : 99.67472339617267%\n",
      "epoch: 41, Val Accuarcy : 99.67472339617267%\n",
      "epoch: 42, Val Accuarcy : 99.68659480507146%\n",
      "epoch: 43, Val Accuarcy : 99.68659480507146%\n",
      "epoch: 44, Val Accuarcy : 99.68659480507146%\n",
      "epoch: 45, Val Accuarcy : 99.70321477752981%\n",
      "epoch: 46, Val Accuarcy : 99.71152476375896%\n",
      "epoch: 47, Val Accuarcy : 99.72814473621729%\n",
      "epoch: 48, Val Accuarcy : 99.70321477752981%\n",
      "epoch: 49, Val Accuarcy : 99.6972790730804%\n",
      "epoch: 50, Val Accuarcy : 99.68896908685123%\n",
      "epoch: 51, Val Accuarcy : 99.71389904553872%\n",
      "epoch: 52, Val Accuarcy : 99.69965335486015%\n",
      "epoch: 53, Val Accuarcy : 99.71389904553872%\n",
      "epoch: 54, Val Accuarcy : 99.71389904553872%\n",
      "epoch: 55, Val Accuarcy : 99.69965335486015%\n",
      "epoch: 56, Val Accuarcy : 99.71508618642861%\n",
      "epoch: 57, Val Accuarcy : 99.71627332731849%\n",
      "epoch: 58, Val Accuarcy : 99.69965335486015%\n",
      "epoch: 59, Val Accuarcy : 99.73170615888694%\n",
      "epoch: 60, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 61, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 62, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 63, Val Accuarcy : 99.71983474998812%\n",
      "epoch: 64, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 65, Val Accuarcy : 99.72102189087802%\n",
      "epoch: 66, Val Accuarcy : 99.70202763663991%\n",
      "epoch: 67, Val Accuarcy : 99.73764186333635%\n",
      "epoch: 68, Val Accuarcy : 99.71983474998812%\n",
      "epoch: 69, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 70, Val Accuarcy : 99.71983474998812%\n",
      "epoch: 71, Val Accuarcy : 99.74120328600598%\n",
      "epoch: 72, Val Accuarcy : 99.72220903176789%\n",
      "epoch: 73, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 74, Val Accuarcy : 99.72220903176789%\n",
      "epoch: 75, Val Accuarcy : 99.72577045443754%\n",
      "epoch: 76, Val Accuarcy : 99.72695759532742%\n",
      "epoch: 77, Val Accuarcy : 99.72102189087802%\n",
      "epoch: 78, Val Accuarcy : 99.73882900422623%\n",
      "epoch: 79, Val Accuarcy : 99.72339617265777%\n",
      "epoch: 80, Val Accuarcy : 99.73645472244645%\n",
      "epoch: 81, Val Accuarcy : 99.72458331354765%\n",
      "epoch: 82, Val Accuarcy : 99.73645472244645%\n",
      "epoch: 83, Val Accuarcy : 99.75307469490478%\n",
      "epoch: 84, Val Accuarcy : 99.75307469490478%\n",
      "epoch: 85, Val Accuarcy : 99.73526758155657%\n",
      "epoch: 86, Val Accuarcy : 99.73051901799705%\n",
      "epoch: 87, Val Accuarcy : 99.71864760909824%\n",
      "epoch: 88, Val Accuarcy : 99.73051901799705%\n",
      "epoch: 89, Val Accuarcy : 99.75426183579468%\n",
      "epoch: 90, Val Accuarcy : 99.73526758155657%\n",
      "epoch: 91, Val Accuarcy : 99.73645472244645%\n",
      "epoch: 92, Val Accuarcy : 99.73645472244645%\n",
      "epoch: 93, Val Accuarcy : 99.73170615888694%\n",
      "epoch: 94, Val Accuarcy : 99.73170615888694%\n",
      "epoch: 95, Val Accuarcy : 99.7590103993542%\n",
      "epoch: 96, Val Accuarcy : 99.73170615888694%\n",
      "epoch: 97, Val Accuarcy : 99.73645472244645%\n",
      "epoch: 98, Val Accuarcy : 99.73645472244645%\n",
      "epoch: 99, Val Accuarcy : 99.73170615888694%\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    for batch_idx, data in enumerate(train_loader_diff):\n",
    "        x_train, y_train = data[0].to(device), data[1].to(device)\n",
    "        hypothesis = net_diff(x_train)\n",
    "        cost = criterion(hypothesis, y_train)\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer_diff.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer_diff.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader_diff:\n",
    "            x_val, y_val = data\n",
    "            hypothesis = net_diff(x_val)\n",
    "            prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "            correct_prediction = prediction.float() == y_val  # 실제값과 일치하는 경우만 True로 간주\n",
    "            val_accuarcy = correct_prediction.sum().item() / len(correct_prediction)  # 정확도를 계산\n",
    "            print(f\"epoch: {epoch}, Val Accuarcy : {val_accuarcy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "proved-magazine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Val Accuarcy : 97.51768839925923%\n",
      "epoch: 1, Val Accuarcy : 99.67947195973218%\n",
      "epoch: 2, Val Accuarcy : 99.72102189087802%\n",
      "epoch: 3, Val Accuarcy : 99.83617455719644%\n",
      "epoch: 4, Val Accuarcy : 99.8634787976637%\n",
      "epoch: 5, Val Accuarcy : 99.86110451588395%\n",
      "epoch: 6, Val Accuarcy : 99.84685882520537%\n",
      "epoch: 7, Val Accuarcy : 99.89671874258038%\n",
      "epoch: 8, Val Accuarcy : 99.89197017902084%\n",
      "epoch: 9, Val Accuarcy : 99.83973597986609%\n",
      "epoch: 10, Val Accuarcy : 99.8694145021131%\n",
      "epoch: 11, Val Accuarcy : 99.86704022033335%\n",
      "epoch: 12, Val Accuarcy : 99.8955316016905%\n",
      "epoch: 13, Val Accuarcy : 99.91215157414882%\n",
      "epoch: 14, Val Accuarcy : 99.90384158791966%\n",
      "epoch: 15, Val Accuarcy : 99.8824730519018%\n",
      "epoch: 16, Val Accuarcy : 99.49427798091077%\n",
      "epoch: 17, Val Accuarcy : 99.88009877012203%\n",
      "epoch: 18, Val Accuarcy : 99.91096443325894%\n",
      "epoch: 19, Val Accuarcy : 99.9133387150387%\n",
      "epoch: 20, Val Accuarcy : 99.91690013770834%\n",
      "epoch: 21, Val Accuarcy : 99.91571299681846%\n",
      "epoch: 22, Val Accuarcy : 99.91215157414882%\n",
      "epoch: 23, Val Accuarcy : 99.91215157414882%\n",
      "epoch: 24, Val Accuarcy : 99.9192744194881%\n",
      "epoch: 25, Val Accuarcy : 99.91452585592859%\n",
      "epoch: 26, Val Accuarcy : 99.89790588347024%\n",
      "epoch: 27, Val Accuarcy : 99.90265444702978%\n",
      "epoch: 28, Val Accuarcy : 99.9192744194881%\n",
      "epoch: 29, Val Accuarcy : 99.89671874258038%\n",
      "epoch: 30, Val Accuarcy : 99.91690013770834%\n",
      "epoch: 31, Val Accuarcy : 99.88128591101191%\n",
      "epoch: 32, Val Accuarcy : 99.91452585592859%\n",
      "epoch: 33, Val Accuarcy : 99.92402298304764%\n",
      "epoch: 34, Val Accuarcy : 99.92521012393752%\n",
      "epoch: 35, Val Accuarcy : 99.87416306567263%\n",
      "epoch: 36, Val Accuarcy : 99.92521012393752%\n",
      "epoch: 37, Val Accuarcy : 99.92283584215774%\n",
      "epoch: 38, Val Accuarcy : 99.92521012393752%\n",
      "epoch: 39, Val Accuarcy : 99.87416306567263%\n",
      "epoch: 40, Val Accuarcy : 99.90384158791966%\n",
      "epoch: 41, Val Accuarcy : 99.89197017902084%\n",
      "epoch: 42, Val Accuarcy : 99.9192744194881%\n",
      "epoch: 43, Val Accuarcy : 99.88603447457145%\n",
      "epoch: 44, Val Accuarcy : 99.92758440571727%\n",
      "epoch: 45, Val Accuarcy : 99.92877154660715%\n",
      "epoch: 46, Val Accuarcy : 99.8955316016905%\n",
      "epoch: 47, Val Accuarcy : 99.89315731991073%\n",
      "epoch: 48, Val Accuarcy : 99.92164870126786%\n",
      "epoch: 49, Val Accuarcy : 99.91690013770834%\n",
      "epoch: 50, Val Accuarcy : 99.93352011016667%\n",
      "epoch: 51, Val Accuarcy : 99.88009877012203%\n",
      "epoch: 52, Val Accuarcy : 99.91452585592859%\n",
      "epoch: 53, Val Accuarcy : 99.93589439194643%\n",
      "epoch: 54, Val Accuarcy : 99.90028016525001%\n",
      "epoch: 55, Val Accuarcy : 99.93708153283632%\n",
      "epoch: 56, Val Accuarcy : 99.93708153283632%\n",
      "epoch: 57, Val Accuarcy : 99.93708153283632%\n",
      "epoch: 58, Val Accuarcy : 99.9382686737262%\n",
      "epoch: 59, Val Accuarcy : 99.92877154660715%\n",
      "epoch: 60, Val Accuarcy : 99.92639726482739%\n",
      "epoch: 61, Val Accuarcy : 99.92877154660715%\n",
      "epoch: 62, Val Accuarcy : 99.92639726482739%\n",
      "epoch: 63, Val Accuarcy : 99.90977729236906%\n",
      "epoch: 64, Val Accuarcy : 99.92758440571727%\n",
      "epoch: 65, Val Accuarcy : 99.9192744194881%\n",
      "epoch: 66, Val Accuarcy : 99.92283584215774%\n",
      "epoch: 67, Val Accuarcy : 99.93708153283632%\n",
      "epoch: 68, Val Accuarcy : 99.92283584215774%\n",
      "epoch: 69, Val Accuarcy : 99.9382686737262%\n",
      "epoch: 70, Val Accuarcy : 99.90384158791966%\n",
      "epoch: 71, Val Accuarcy : 99.92639726482739%\n",
      "epoch: 72, Val Accuarcy : 99.92639726482739%\n",
      "epoch: 73, Val Accuarcy : 99.93945581461607%\n",
      "epoch: 74, Val Accuarcy : 99.92877154660715%\n",
      "epoch: 75, Val Accuarcy : 99.92639726482739%\n",
      "epoch: 76, Val Accuarcy : 99.92877154660715%\n",
      "epoch: 77, Val Accuarcy : 99.9382686737262%\n",
      "epoch: 78, Val Accuarcy : 99.92521012393752%\n",
      "epoch: 79, Val Accuarcy : 99.9382686737262%\n",
      "epoch: 80, Val Accuarcy : 99.9382686737262%\n",
      "epoch: 81, Val Accuarcy : 99.93945581461607%\n",
      "epoch: 82, Val Accuarcy : 99.93945581461607%\n",
      "epoch: 83, Val Accuarcy : 99.92639726482739%\n",
      "epoch: 84, Val Accuarcy : 99.92877154660715%\n",
      "epoch: 85, Val Accuarcy : 99.92521012393752%\n",
      "epoch: 86, Val Accuarcy : 99.91096443325894%\n",
      "epoch: 87, Val Accuarcy : 99.93114582838692%\n",
      "epoch: 88, Val Accuarcy : 99.91690013770834%\n",
      "epoch: 89, Val Accuarcy : 99.90977729236906%\n",
      "epoch: 90, Val Accuarcy : 99.91571299681846%\n",
      "epoch: 91, Val Accuarcy : 99.74120328600598%\n",
      "epoch: 92, Val Accuarcy : 99.92995868749703%\n",
      "epoch: 93, Val Accuarcy : 99.90502872880953%\n",
      "epoch: 94, Val Accuarcy : 99.91215157414882%\n",
      "epoch: 95, Val Accuarcy : 99.92758440571727%\n",
      "epoch: 96, Val Accuarcy : 99.94657865995536%\n",
      "epoch: 97, Val Accuarcy : 99.9382686737262%\n",
      "epoch: 98, Val Accuarcy : 99.9074030105893%\n",
      "epoch: 99, Val Accuarcy : 99.94657865995536%\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    for batch_idx, data in enumerate(train_loader_each):\n",
    "        x_train, y_train = data[0].to(device), data[1].to(device)\n",
    "        hypothesis = net_each(x_train)\n",
    "        cost = criterion(hypothesis, y_train)\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer_each.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer_each.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader_each:\n",
    "            x_val, y_val = data\n",
    "            hypothesis = net_each(x_val)\n",
    "            prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "            correct_prediction = prediction.float() == y_val  # 실제값과 일치하는 경우만 True로 간주\n",
    "            val_accuarcy = correct_prediction.sum().item() / len(correct_prediction)  # 정확도를 계산\n",
    "            print(f\"epoch: {epoch}, Val Accuarcy : {val_accuarcy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-round",
   "metadata": {},
   "source": [
    "# 개선 계획\n",
    "학습 과정에서 accuracy가 높아지지 않은 것으로, 제대로 학습되지 않는 상태인것으로 확인  \n",
    "input에 대한 조절로 결과를 얻고자한다\n",
    "1. RSSI 값 연산 시 재정의:   \n",
    "현재 해당 비컨에 해당하는 RSSI가 없으면, 0으로 넣어주고 비교하고있다.  \n",
    "그결과, null데이터와 -90dB의 차이가, null데이터와 -10dB의 차이보다 더 큰 상태이다.  \n",
    "null값에 대해 -100을 넣어주고 연산하는 방식으로 오류를 줄여야 한다.  \n",
    "2. Input 범위 재설정:  \n",
    "1의 적용 이후, 실제 input으로 들어갈 값들은 -100 ~ -1 사이의 값이다.  \n",
    "input에 100을 더한 후 100으로 나눠주어, input들이 0 ~ 1 사이의 범위에 있도록 normalize 해줄 계획이다\n",
    "3. Input Data 추가:  \n",
    "현재는 두 데이터간의 '차의 절댓값' 만을 넣어주고 있어서, 데이터 dimension이 9이하인 상태이다. (적은 편)  \n",
    "차만을 사용하는 과정에서, 각 데이터의 RF measurement들이 버려지게 된다.  \n",
    "4. Input의 다원화:  \n",
    "현재 사용하고 있지 않은 기압값등을 어떻게 활용할지 고려한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "western-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_diff.state_dict(), \"./model/diff\")\n",
    "torch.save(net_each.state_dict(), \"./model/each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-allocation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
